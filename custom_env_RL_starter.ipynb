{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter / test code for RL group project using computer vision and custom environment\n",
    "\n",
    "set up custom environment (stable baselines framework)\n",
    "\n",
    "Included in custom environment settup:\n",
    "- Get_observation (MSS: https://pypi.org/project/mss/1.0.2/)\n",
    "    - screen capture to observe the game\n",
    "    - Run through opencv for preprocessing to get game shape\n",
    "- Send commands (pydirectinput: https://pypi.org/project/PyDirectInput/)\n",
    "- get game over state -- embeded ml (pytesseract ocr: https://pypi.org/project/pytesseract/)\n",
    "    - googles tesseract-ocr engine\n",
    "    - determine when game is done by extracting text from end game state\n",
    "- Reward function\n",
    "\n",
    "Please play around with the code and get comfortable with the following libraries as we will most likely utilize these to build and train our RL model for the game 'Getting Over It'. To begin testing test the code with the chrome dino game ( chrome://dino/ ) and adjust the game_location and game_over_location values to match your screen resolution. After this check out the scratch verion of Getting Over It Issac found https://scratch.mit.edu/projects/389464290/\n",
    "\n",
    "The following code has derived from this RL YouTube course: https://www.youtube.com/watch?v=dWmJ5CXSKdw&t=30489s&ab_channel=NicholasRenotte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch (larger download)\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# install stable-baselines + protobuf\n",
    "# !pip install stable-baselines3[extra] protobuf==3.20.*\n",
    "\n",
    "# install mss - cross platfrom multiple screenshot module in pure python\n",
    "# !pip install --upgrade mss\n",
    "\n",
    "# install pydirectinput\n",
    "# !pip install pydirectinput\n",
    "\n",
    "# install pytesseract (python wrapper for google tesseract.. need google tesseract installed before wrapper)\n",
    "#\n",
    "# prereqs: python 3.6+, PIL or Pillow, google terreract ocr (download binary from github)\n",
    "#\n",
    "# pip install --upgrade Pillow\n",
    "# install google tesseract binary https://tesseract-ocr.github.io/tessdoc/Installation.html\n",
    "# youtube install guide: https://www.youtube.com/watch?v=2kWvk4C1pMo&ab_channel=JayMartMedia\n",
    "# \n",
    "# !pip install pytesseract\n",
    "\n",
    "# install openai gym\n",
    "# !pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydirectinput    # sending commands\n",
    "import cv2              # frame processing\n",
    "import pytesseract      # ocr for reading text -- game over\n",
    "import time\n",
    "import numpy as np\n",
    "from mss import mss     # screen capture\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# environment\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Environment (Custom openAI gym env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScreenCaptureGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: \n",
    "        # setup spaces \n",
    "        self.observation_space = Box(low=0, high=255, shape=(1, 83, 100), dtype=np.uint8)\n",
    "        # TODO: \n",
    "        # number of actions\n",
    "        self.action_space = Discrete(3)\n",
    "        # define extraction params for game\n",
    "        self.cap = mss()\n",
    "\n",
    "        \n",
    "        # TODO: adjust values will depend on screen resolution\n",
    "        # location for game captures\n",
    "        self.game_location = {'top': 800, 'left': 0, 'width': 1200, 'height': 1000}\n",
    "        self.game_over_location = {'top': 950, 'left': 1000, 'width': 1200, 'height': 200}\n",
    "        \n",
    "    # TODO: determine actions, look into pydirect input and test different action maps\n",
    "    # hint: limit actions to improve performance, can we use x y mouse values to simulate cw and cc rotation? what about jumping up?\n",
    "    # step this is what happens every frame   \n",
    "    def step(self, action):\n",
    "        # TODO:\n",
    "        # Action keys: 0 = space, 1 = down, 2 = no action\n",
    "        action_map = {\n",
    "            0: 'space',\n",
    "            1: 'down',\n",
    "            2: 'no_op'\n",
    "        }\n",
    "        if action != 2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "        # check if game is done\n",
    "        is_game_over, game_over_capture = self.get_game_over()\n",
    "        # get new observation\n",
    "        new_observation = self.get_observation()\n",
    "        # TODO: what should our reward be? can we use pytesseract to extract height/score?\n",
    "        # reward - get point for every frame\n",
    "        reward = 1\n",
    "        # info dictionary, required by stable baseline\n",
    "        info = {}\n",
    "        \n",
    "        return new_observation, reward, info\n",
    "        \n",
    "    # TODO: can we improve this? do we need this? will this work better in a python script?\n",
    "    # visulize game\n",
    "    def render(self):\n",
    "        cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "            \n",
    "    # reset the game\n",
    "    # TODO: how do we reset our game?\n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation()\n",
    "    \n",
    "    # close render window\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def get_observation(self):\n",
    "        # get screen cap\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        # grayscale 3 channels -> single channel\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        # resize (width, height)\n",
    "        resized = cv2.resize(gray, (100, 83))\n",
    "        # add channels first --> required stable baselines\n",
    "        channel = np.reshape(resized, (1, 83, 100))\n",
    "        return channel\n",
    "    \n",
    "    # TODO: how to determine game over? pytesseract to extract text data from screen?\n",
    "    # hint: scratch game allows displaying game variable data\n",
    "    # get game over text using OCR to signal game over\n",
    "    def get_game_over(self):\n",
    "        game_over_capture = np.array(self.cap.grab(self.game_over_location))[:,:,:3]\n",
    "        is_game_over = False\n",
    "        # game over text -- test and add possible misspelled 'game' results\n",
    "        valid_strings = ['GAME', 'GAHE', 'GANE', 'GAAM']\n",
    "        # OCR, takes image and extracts text (not 100% accurate)\n",
    "        ocr_res = pytesseract.image_to_string(game_over_capture)[:4]\n",
    "        if ocr_res in valid_strings:\n",
    "            is_game_over = True\n",
    "        return is_game_over, game_over_capture\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ScreenCaptureGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.get_observation()[0].shape\n",
    "# plt.imshow(env.get_observation()[0])\n",
    "\n",
    "# show game state - converted back to RGB\n",
    "plt.imshow(cv2.cvtColor(env.get_observation()[0], cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(env.get_game_over()[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_game_over, game_over_capture = env.get_game_over()\n",
    "\n",
    "is_game_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.observation_space.sample()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ScreenCaptureGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(observation[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_game_over, game_over_capture = env.get_game_over()\n",
    "\n",
    "#is_game_over\n",
    "# plt.imshow(game_over_capture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Test Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
